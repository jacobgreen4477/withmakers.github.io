<!DOCTYPE html>
<html>

<head>

    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-55499LK');</script>
    <!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	
    <!-- Favicon Icon -->
    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.ico">

    <title>제이콥의 &lt;br&gt; 머신러닝, 딥러닝, 인공지능 저장소</title>
    <meta name="description"
          content="">

    <link rel="canonical" href="http://localhost:4000/search.html">
    <link rel="alternate" type="application/rss+xml" title="제이콥의 <br> 머신러닝, 딥러닝, 인공지능 저장소" href="http://localhost:4000/feed.xml">

    <script type="text/javascript" src="/bower_components/jquery/dist/jquery.min.js"></script>

    <!-- Third-Party CSS -->
    <link rel="stylesheet" href="/bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="/bower_components/octicons/octicons/octicons.css">
    <link rel="stylesheet" href="/bower_components/hover/css/hover-min.css">
    <link rel="stylesheet" href="/bower_components/primer-markdown/dist/user-content.min.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- My CSS -->
    <link rel="stylesheet" href="/assets/css/common.css">

    <!-- CSS set in page -->
    
    <link rel="stylesheet" href="/assets/css/index.css">
    
    <link rel="stylesheet" href="/assets/css/sidebar-popular-repo.css">
    

    <!-- CSS set in layout -->
    

    <script type="text/javascript" src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>

</head>


    <body>
    
    <!-- Google Tag Manager (noscript) -->
	<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-55499LK"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<!-- End Google Tag Manager (noscript) -->

    <style>
.dropdown {
    position: relative;
    display: inline-block;
}

.dropdown-content {
    display: none;
    position: absolute;
    background-color: #f1f1f1;
    min-width: 160px;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
    z-index: 1;
}

.dropdown-content a {
    color: black;
    padding: 12px 16px;
    text-decoration: none;
    display: block;
}

.dropdown-content a:hover {background-color: #ddd;}

.dropdown:hover .dropdown-content {display: block;}

.dropdown:hover .dropbtn {background-color: #3e8e41;}
</style>

<header class="site-header" style="background-color:white; margin-top:0">
<!--<header class="site-header" style=background-color:white;>-->    
    
    <div class="container">
        <span id="site-header-brand">
            <!--<a href="https://jacobgreen4477.github.io/"><img src="https://raw.githubusercontent.com/jacobgreen4477/jacobgreen4477.github.io/master/_img/deepbro.png" style="max-width:25%;max-height:25%;"></img></a>-->
        </span>
        <nav class="site-header-nav" role="navigation">
            

              
              <a href="/"
                 class=" site-header-nav-item hvr-underline-from-center"
                 target=""
                 title="Home"
                 style="color:black">
                  Home
              </a>
               


              


              


            

               


              
                <div class="dropdown">
                  <a class="site-header-nav-item hvr-underline-from-center" style="color:black">Project</a>
                  <div class="dropdown-content">
                     
                      <a href="/open-source">Open Source</a>
                     
                      <a href="/newsletter">News Letter</a>
                     
                      <a href="/blog">Research Title</a>
                     
                      <a href="/master-code">Machine Learning Master Code</a>
                    
                  </div>
                </div>
              


              


            
        </nav>
    </div>
</header>


        <div class="content">
            <section class="jumbotron" style="background-image: url(https://raw.githubusercontent.com/2econsulting/2econsulting.github.io/master/_img/nn.gif);background-repeat: no-repeat; background-size: 100% 100%;">
<!--<section class="jumbotron">-->   
    <div class="container">
        <h1>제이콥의 <br> 머신러닝, 딥러닝, 인공지능 저장소</h1>
        <div id="jumbotron-meta-info">
            <span class="meta-info hvr-grow">
                <span class="octicon octicon-organization"></span>
                <a href="https://www.idbins.com/Index.jsp" target="_blank">DB손해보험</a>
            </span> 
            <span class="meta-info hvr-grow">
                <span class="octicon octicon-mark-github"></span>
                <a href="https://github.com/jacobgreen4477" target="_blank">깃허브</a>
            </span> 
            <!--
            <span class="meta-info hvr-grow">
                <span class="octicon octicon-plus"></span>
                <a href="https://2econsulting.github.io/subscribe" target="_blank">구독</a>
            </span>
          -->
            <span class="meta-info hvr-grow">
                <span class="octicon octicon-mail"></span>
                <a href="https://flaskapp2e.herokuapp.com" target="_blank">PFMS</a>
            </span>
            <span class="meta-info hvr-grow">
                <span class="octicon octicon-graph"></span>
                <a href="https://2econsulting.github.io/request/request" target="_blank">분석request</a>
            </span>
        </div>
    </div>
</section>

<section class="content container">

    <div class="row">

        <!-- Post List -->
        <div class="col-md-8">

          <form action="/search.html" method="get">
            <label for="search-box"></label>
            <input type="text" id="search-box" name="query">
            <input type="submit" value="검색">
          </form>

          <br>

          <ul id="search-results"></ul>

          <script>
            window.store = {
              
                "etc-2019-01-07-db-html": {
                  "title": "DB손해보험으로 이직",
                  "author": "",
                  "category": "[&quot;etc&quot;]",
                  "content": "(냉무)",
                  "url": "/etc/2019/01/07/DB.html"
                }
                ,
              
                "newsletters-2018-12-29-newsletter-html": {
                  "title": "2018.12.29. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  no new articleAnalytics Vidhya NEWS TITLE  The 25 Best Data Science Projects on GitHub from 2018 that you Should Not MissKeyword(freq): model(10), project(10), researcher(7), task(7), resource(6), image(5), release(5), tool(5), example(4), framework(4)Machine Learning Mastery NEWS TITLE      How to Develop a Weighted Average Ensemble for Deep Learning Neural NetworksKeyword(freq): weight(31), model(28), value(12), result(9), ensemble(8), point(7), example(5), dot(4), function(4), prediction(4)        How to Reduce Variance in the Final Deep Learning Model With a Horizontal Voting EnsembleKeyword(freq): model(41), epoch(14), point(8), prediction(7), dataset(5), score(5), example(4), result(4), curve(3), dot(3)        How to Create a Random-Split, Cross-Validation, and Bagging Ensemble for Deep Learning in KerasKeyword(freq): model(45), ensemble(10), example(10), prediction(10), split(10), dot(8), score(8), set(8), method(7), point(6)  ",
                  "url": "/newsletters/2018/12/29/newsletter.html"
                }
                ,
              
                "newsletters-2018-12-22-newsletter-html": {
                  "title": "2018.12.22. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Hackathon Winner Interview: Penn State | Kaggle University ClubKeyword(freq): competition(4), aspiration(3), team(3), approach(2), art(2), idea(2), kernel(2), oake(2), algorithm(1), book(1)Data Camp NEWS TITLE  DataCamp Announces New FundingKeyword(freq): analytics(3), company(3), datacamp(2), project(2), capability(1), exercise(1), expert(1), hint(1), integration(1), learner(1)Analytics Vidhya NEWS TITLE      DataHack Radio #14: Quantum Computing and Quantum Machine Learning with Dr. Mandaar PandeKeyword(freq): computer(3), atom(2), folk(2), mechanic(2), optic(2), physic(2), transistor(2), application(1), aspect(1), avenue(1)        A Technical Overview of AI &amp; ML (NLP, Computer Vision, Reinforcement Learning) in 2018 &amp; Trends for 2019Keyword(freq): model(9), task(7), application(6), time(6), company(5), development(5), image(5), thought(4), analytics(3), embedding(3)        Top Highlights from the Amazing Machine Learning Tutorials Presented at NeurIPS (NIPS) 2018Keyword(freq): method(9), neurip(9), speaker(9), system(9), researcher(7), session(7), topic(7), feature(5), model(5), term(5)        A Comprehensive Guide to Digital Marketing and Analytics Every Data Science Professional Must ReadKeyword(freq): analytics(24), media(21), tag(16), cooky(9), customer(9), advertiser(8), visitor(7), impression(6), tool(6), adword(5)  Machine Learning Mastery NEWS TITLE      How to Reduce the Variance of Deep Learning Models in Keras Using Model Averaging EnsemblesKeyword(freq): model(29), prediction(12), score(8), kera(6), point(6), sample(6), result(5), ensemble(4), variable(4), curve(3)        Ensemble Methods for Deep Learning Neural Networks to Reduce Variance and Improve PerformanceKeyword(freq): model(37), network(32), prediction(29), method(9), weight(9), ensemble(7), result(7), error(5), layer(5), input(4)        Introduction to Regularization to Reduce Overfitting of Deep Learning Neural NetworksKeyword(freq): network(12), method(9), weight(8), example(7), parameter(6), input(5), case(4), change(4), layer(4), node(4)  ",
                  "url": "/newsletters/2018/12/22/newsletter.html"
                }
                ,
              
                "newsletters-2018-12-15-newsletter-html": {
                  "title": "2018.12.15. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  Enter the #DataFramedChallenge for a chance to be on an upcoming podcast segment.Keyword(freq): tweet(2), chance(1), duplicate(1), episode(1), itune(1), NA(NA), NA(NA), NA(NA), NA(NA), NA(NA)Analytics Vidhya NEWS TITLE      WNS Hackathon Solutions by Top FinishersKeyword(freq): solution(5), analytics(4), hackathon(3), model(3), participant(3), employee(2), registration(2), row(2), submission(2), winner(2)        Building a Face Detection Model from Video using Deep Learning (Python Implementation)Keyword(freq): application(8), case(4), technique(3), tool(3), attendee(2), comment(2), detail(2), face(2), image(2), suggestion(2)  Machine Learning Mastery NEWS TITLE      How to Improve Deep Learning Model Robustness by Adding NoiseKeyword(freq): value(7), circle(5), dataset(5), kera(5), layer(5), model(5), sample(5), epoch(4), observation(4), point(4)        Train Neural Networks With Noise to Reduce OverfittingKeyword(freq): network(16), variable(10), input(9), weight(9), example(5), type(5), model(4), point(4), sample(4), activation(3)        How to Stop Training Deep Neural Networks At the Right Time Using Early StoppingKeyword(freq): callback(10), epoch(8), model(7), network(4), observation(4), problem(4), result(4), sample(4), set(4), dataset(3)  ",
                  "url": "/newsletters/2018/12/15/newsletter.html"
                }
                ,
              
                "newsletters-2018-12-08-newsletter-html": {
                  "title": "2018.12.08. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Announcing Kaggle integration with Google Data StudioKeyword(freq): user(8), dataset(5), dashboard(4), story(3), finding(2), kernel(2), analytics(1), blog(1), decision(1), developer(1)Data Camp NEWS TITLE  no new articleAnalytics Vidhya NEWS TITLE      A Practical Guide to Object Detection using the Popular YOLO Framework &lt;U+2013&gt; Part III (with Python codes)Keyword(freq): box(38), object(19), algorithm(7), coordinate(5), grid(5), iou(5), prediction(5), probability(5), value(5), image(4)        5 Best Machine Learning GitHub Repositories &amp; Reddit Discussions (November 2018)Keyword(freq): comment(4), developer(2), folk(2), neuron(2), repository(2), representation(2), researcher(2), resource(2), algorithm(1), ambition(1)        Building a Random Forest from Scratch &amp; Understanding Real-World Data Products (ML for Programmers &lt;U+2013&gt; Part 3)Keyword(freq): point(10), technique(10), feature(9), result(9), prediction(8), step(6), value(6), application(5), model(5), tree(5)        A Practical Guide to Object Detection using the Popular YOLO Framework &lt;U+2013&gt; Part III (with Python codes) Keyword(freq): box(38), object(19), algorithm(7), coordinate(5), grid(5), iou(5), prediction(5), probability(5), value(5), image(4)  Machine Learning Mastery NEWS TITLE      A Gentle Introduction to Early Stopping to Avoid Overtraining Deep Learning Neural Network ModelsKeyword(freq): network(12), epoch(9), model(7), time(4), trigger(4), value(4), dataset(3), parameter(3), result(3), set(3)        How to Reduce Overfitting With Dropout Regularization in KerasKeyword(freq): input(12), layer(11), circle(5), output(5), sample(5), dataset(4), kera(4), model(4), network(4), observation(4)        A Gentle Introduction to Dropout for Regularizing Deep Neural NetworksKeyword(freq): network(29), layer(18), unit(11), node(10), weight(9), model(7), output(5), result(5), problem(4), rate(4)  ",
                  "url": "/newsletters/2018/12/08/newsletter.html"
                }
                ,
              
                "newsletters-2018-12-01-newsletter-html": {
                  "title": "2018.12.01. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE      Designing a Self-Learning Tic-Tac-Toe PlayerKeyword(freq): community(1), dataset(1), embedding(1), kernel(1), network(1), result(1), right(1), war(1), NA(NA), NA(NA)        LogicAI and Kaggle team up on Kaggle Days events in 2019 and beyond!Keyword(freq): event(5), grandmaster(2), logicai(2), master(2), participant(2), application(1), effort(1), enthusiast(1), fan(1), hometown(1)  Data Camp NEWS TITLE      Request for Proposal: Topical Projects for January 2019Keyword(freq): project(6), faq(2), instructor(2), achievement(1), advantage(1), analysis(1), benefit(1), hour(1), idea(1), outsource(1)        Cathy O’Neil discusses the current lack of fairness in artificial intelligence and much more.Keyword(freq): algorithm(36), company(10), krono(9), question(9), scientist(8), death(7), teacher(6), decision(5), loop(5), problem(5)  Analytics Vidhya NEWS TITLE      Tutorial on Text Classification (NLP) using ULMFiT and fastai Library in PythonKeyword(freq): model(13), dataset(6), task(5), result(4), technique(4), kwarg(3), label(3), thank(3), application(2), document(2)        Highlights from DataHack Summit 2018 &lt;U+2013&gt; a Truly Overwhelming and Resounding Success!Keyword(freq): attendee(3), leader(3), topic(3), workshop(3), folk(2), professional(2), session(2), analytics(1), auditorium(1), career(1)  Machine Learning Mastery NEWS TITLE      How to Reduce Generalization Error in Deep Neural Networks With Activity Regularization in KerasKeyword(freq): dataset(6), model(6), observation(6), set(6), circle(5), kera(5), plot(4), sample(4), network(3), output(3)        Activation Regularization for Reducing Generalization Error in Deep Learning Neural NetworksKeyword(freq): feature(23), value(12), model(10), activation(9), representation(9), network(8), autoencoder(5), example(5), type(5), weight(4)        How to Reduce Overfitting in Deep Neural Networks Using Weight Constraints in KerasKeyword(freq): constraint(15), weight(12), set(6), dataset(4), kera(4), norm(4), observation(4), sample(4), layer(3), model(3)  ",
                  "url": "/newsletters/2018/12/01/newsletter.html"
                }
                ,
              
                "newsletters-2018-11-24-newsletter-html": {
                  "title": "2018.11.24. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  Wes McKinney discusses data science tool building.Keyword(freq): pandas(60), project(22), developer(20), tool(15), lab(10), language(10), library(8), problem(8), set(7), statistics(7)Analytics Vidhya NEWS TITLE      4 Secrets for a Future Ready Career in Data ScienceKeyword(freq): job(9), domain(5), scientist(5), process(3), role(3), skill(3), tool(3), business(2), change(2), document(2)        Reinforcement Learning: Introduction to Monte Carlo Learning using the OpenAI Gym ToolkitKeyword(freq): episode(8), return(5), state(5), action(4), probability(4), reward(4), method(3), algorithm(2), article(2), bandit(2)  Machine Learning Mastery NEWS TITLE      A Gentle Introduction to Weight Constraints to Reduce Generalization Error in Deep LearningKeyword(freq): weight(37), constraint(13), network(12), model(5), method(4), variable(4), detector(3), idea(3), layer(3), penalty(3)        How to Reduce Overfitting of a Deep Learning Model with Weight RegularizationKeyword(freq): model(8), result(8), value(8), dataset(6), network(6), set(6), epoch(4), example(4), kera(4), moon(4)        Use Weight Regularization to Reduce Overfitting of Deep Learning ModelsKeyword(freq): weight(45), network(12), value(10), model(7), variable(7), input(5), change(4), penalty(4), approach(3), coefficient(3)  ",
                  "url": "/newsletters/2018/11/24/newsletter.html"
                }
                ,
              
                "newsletters-2018-11-17-newsletter-html": {
                  "title": "2018.11.17. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Data Notes: Impact of Game of Thrones on US Baby NamesKeyword(freq): throne(2), baby(1), dataset(1), fan(1), history(1), kaggler(1), kernel(1), mapplot(1), right(1), NA(NA)Data Camp NEWS TITLE  Angela Bassa discusses managing data science teams and much more.Keyword(freq): folk(29), question(20), term(13), company(8), heuristic(7), scientist(7), robot(6), team(6), answer(5), expert(5)Analytics Vidhya NEWS TITLE  DataHack Summit 2018 is Almost Here &lt;U+2013&gt; WHERE HUMANS MEET ARTIFICIAL INTELLIGENCEKeyword(freq): session(7), workshop(6), leader(4), practitioner(4), talk(4), domain(3), startup(3), topic(3), analytics(2), concept(2)Machine Learning Mastery NEWS TITLE      How to Grid Search Deep Learning Models for Time Series ForecastingKeyword(freq): model(20), hyperparameter(19), configuration(16), observation(16), value(11), score(7), prediction(6), sample(5), element(4), layer(4)        How to Develop LSTM Models for Time Series ForecastingKeyword(freq): step(55), sample(29), model(22), problem(13), feature(11), lstm(8), component(7), type(7), value(7), variable(7)        How to Develop Convolutional Neural Network Models for Time Series ForecastingKeyword(freq): step(49), sample(26), model(11), component(8), array(7), feature(7), problem(7), value(7), variable(7), cnn(6)  ",
                  "url": "/newsletters/2018/11/17/newsletter.html"
                }
                ,
              
                "newsletters-2018-11-10-newsletter-html": {
                  "title": "2018.11.10. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  New: Maintained DatasetsKeyword(freq): dataset(5), api(1), call(1), comment(1), description(1), example(1), kaggler(1), metadata(1), organization(1), question(1)Data Camp NEWS TITLE  Peter Bull discusses the importance of human-centered design in data science. Keyword(freq): agent(12), ethic(12), project(12), transaction(11), service(10), scientist(9), video(9), competition(7), tool(7), method(6)Analytics Vidhya NEWS TITLE      Want to Become a Data Engineer? Here’s a Comprehensive List of Resources to get StartedKeyword(freq): book(11), engineer(10), resource(10), application(8), basic(8), scientist(7), example(6), system(6), topic(6), component(5)        A Practical Implementation of the Faster R-CNN Algorithm for Object Detection (Part 2 &lt;U+2013&gt; with Python codes)Keyword(freq): image(10), algorithm(7), object(6), prediction(6), region(6), weight(6), box(5), library(5), cell(4), step(4)  Machine Learning Mastery NEWS TITLE      How to Develop Multilayer Perceptron Models for Time Series ForecastingKeyword(freq): step(47), sample(27), feature(8), array(7), observation(7), problem(7), variable(7), component(6), model(6), value(6)        How to Use the TimeseriesGenerator for Time Series Forecasting in KerasKeyword(freq): sample(27), observation(14), step(12), model(8), feature(6), file(6), output(6), input(5), thank(5), value(5)        A Gentle Introduction to LSTM AutoencodersKeyword(freq): sequence(13), lstm(12), representation(9), feature(7), model(7), step(7), problem(6), thank(6), frame(5), kera(5)  ",
                  "url": "/newsletters/2018/11/10/newsletter.html"
                }
                ,
              
                "newsletters-2018-11-03-newsletter-html": {
                  "title": "2018.11.03. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE      Pulse of the Competition: November EditionKeyword(freq): kernel(4), competition(2), kaggler(2), technique(2), tip(2), winner(2), astrophysic(1), atlas(1), backbone(1), cell(1)        Data Notes: Chinese Tourism’s Impact on TaiwanKeyword(freq): forecast(2), dataset(1), election(1), flower(1), kernel(1), mathematic(1), model(1), provider(1), right(1), subspecy(1)  Data Camp NEWS TITLE  Arnaub Chatterjee discusses artificial intelligence (AI) and machine learning (ML) in healthcare.Keyword(freq): company(33), patient(16), term(15), case(14), algorithm(13), model(9), startup(9), task(9), application(8), method(8)Analytics Vidhya NEWS TITLE      Top 5 Machine Learning GitHub Repositories &amp; Reddit Discussions (October 2018)Keyword(freq): idea(4), model(4), project(4), skill(4), professional(3), scientist(3), thought(3), algorithm(2), detail(2), discussion(2)        An Introduction to Text Summarization using the TextRank Algorithm (with Python implementation)Keyword(freq): sentence(22), article(9), vector(9), page(7), embedding(4), feature(3), score(3), similarity(3), stopword(3), thank(3)        DataHack Radio #13: Data Science and AI in the Oil &amp; Gas Industry with Yogendra Pandey, Ph.D.Keyword(freq): application(3), case(2), network(2), organization(2), rig(2), technique(2), advancement(1), algorithm(1), analytics(1), episode(1)        An Intuitive Guide to Interpret a Random Forest Model using fastai library (Machine Learning for Programmers &lt;U+2013&gt; Part 2)Keyword(freq): feature(26), variable(23), prediction(20), value(17), result(12), category(7), column(7), model(7), row(5), tree(5)        MADRaS: A Multi-Agent DRiving Simulator for Autonomous Driving ResearchKeyword(freq): agent(8), car(4), algorithm(3), behavior(3), driver(3), madra(2), oftorc(2), robot(2), scenario(2), simulator(2)        A Computer Vision Approach to Hand Gesture RecognitionKeyword(freq): gesture(8), value(7), angle(4), feature(4), sensor(4), acceleration(3), axe(2), cluster(2), soldier(2), algorithm(1)  Machine Learning Mastery NEWS TITLE      LSTM Model Architecture for Rare Event Time Series ForecastingKeyword(freq): series(23), network(21), model(8), lstm(7), holiday(6), vector(6), event(5), forecast(4), outlier(4), result(4)        Results From Comparing Classical and Machine Learning Methods for Time Series ForecastingKeyword(freq): method(73), concern(15), result(15), model(14), dataset(9), problem(8), observation(7), finding(6), algorithm(4), forecast(4)        How to Develop Deep Learning Models for Univariate Time Series ForecastingKeyword(freq): observation(33), model(21), sale(21), step(12), feature(11), value(11), hyperparameter(9), network(9), score(9), prediction(8)  ",
                  "url": "/newsletters/2018/11/03/newsletter.html"
                }
                ,
              
                "newsletters-2018-10-27-newsletter-html": {
                  "title": "2018.10.27. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  Cassie Kozyrkov discusses decision making and decision intelligence!Keyword(freq): scientist(16), skill(12), folk(9), maker(9), decision(8), photograph(8), team(8), analytics(7), question(7), assumption(6)Analytics Vidhya NEWS TITLE  Stock Prices Prediction Using Machine Learning and Deep Learning Techniques (with Python codes)Keyword(freq): prediction(21), value(17), technique(13), feature(8), variable(6), algorithm(5), price(5), result(5), factor(4), neighbor(4)Machine Learning Mastery NEWS TITLE      How to Grid Search Naive Methods for Univariate Time Series ForecastingKeyword(freq): observation(26), configuration(23), strategy(14), method(9), model(9), sale(9), value(8), implement(6), result(5), birth(4)        How to Grid Search SARIMA Model Hyperparameters for Time Series Forecasting in PythonKeyword(freq): configuration(29), hyperparameter(11), model(11), observation(11), sale(9), element(5), implement(5), minute(5), parameter(5), birth(4)        How to Grid Search Triple Exponential Smoothing for Time Series Forecasting in PythonKeyword(freq): configuration(24), observation(18), hyperparameter(11), model(9), sale(9), method(7), parameter(7), implement(5), birth(4), forecast(4)  ",
                  "url": "/newsletters/2018/10/27/newsletter.html"
                }
                ,
              
                "newsletters-2018-10-20-newsletter-html": {
                  "title": "2018.10.20. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Data Notes: The Secret of Academic SuccessKeyword(freq): architecture(1), car(1), cnn(1), dataset(1), kernel(1), network(1), review(1), right(1), script(1), truck(1)Data Camp NEWS TITLE      SQL Server, PostgreSQL, MySQL… what’s the difference? Where do I start?Keyword(freq): system(4), table(4), platform(3), question(3), skill(3), student(3), column(2), databasis(2), dialect(2), difference(2)        Project Jupyter and Interactive Computing (Transcript)Keyword(freq): notebook(32), project(27), organization(19), contributor(15), user(13), term(10), tool(10), feature(9), contribution(8), case(7)  Analytics Vidhya NEWS TITLE      Deep Learning in the Trenches: Understanding Inception Network from ScratchKeyword(freq): layer(7), image(5), architecture(4), idea(4), kera(4), author(3), article(2), learning(2), library(2), module(2)        Must Read Books&lt;U+00A0&gt;for Beginners on Machine Learning and Artificial IntelligenceKeyword(freq): book(19), link(11), algorithm(7), author(7), pdf(7), machine(6), technique(4), thank(4), topic(4), aspect(3)        An NLP Approach to Mining Online Reviews using Topic Modeling (with Python codes)Keyword(freq): review(26), topic(11), product(6), consumer(5), term(5), technique(3), thank(3), customer(2), dataset(2), item(2)        DataHack Radio #12: Exploring the Nuts and Bolts of Natural Language Processing with Sebastian RuderKeyword(freq): language(5), media(4), linguistic(3), model(3), technique(3), analytics(2), source(2), algorithm(1), application(1), article(1)  Machine Learning Mastery NEWS TITLE      How to Develop Machine Learning Models for Multivariate Multi-Step Air Pollution Time Series ForecastingKeyword(freq): observation(34), model(28), variable(24), algorithm(20), chunk(18), time(18), row(12), gap(10), hour(9), implement(9)        How to Develop Autoregressive Forecasting Models for Multi-Step Air Pollution Time Series ForecastingKeyword(freq): value(26), plot(25), chunk(21), observation(18), model(17), variable(16), hour(15), time(13), row(10), gap(9)        How to Develop Baseline Forecasts for Multi-Site Multivariate Air Pollution Time Series ForecastingKeyword(freq): chunk(17), method(16), mae(15), observation(14), time(14), variable(11), row(10), forecast(9), site(9), implement(8)  ",
                  "url": "/newsletters/2018/10/20/newsletter.html"
                }
                ,
              
                "newsletters-2018-10-13-newsletter-html": {
                  "title": "2018.10.13. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE      Our Content Library Growth in the Past 3 MonthsKeyword(freq): project(6), effort(2), improvement(2), instructor(2), learner(2), mode(2), skill(2), woman(2), dimension(1), exercise(1)        How is content created at DataCamp? Keyword(freq): instructor(16), project(5), skill(4), student(4), role(3), background(2), developer(2), perform(2), recruiter(2), specification(2)        Andrew Gelman  discusses election forecasting and polling. (Transcript)Keyword(freq): statistics(29), poll(16), survey(13), pollster(11), number(10), assumption(9), politician(7), state(7), challenge(6), fluctuation(6)  Analytics Vidhya NEWS TITLE      A Step-by-Step Introduction to the Basic Object Detection Algorithms (Part 1)Keyword(freq): region(21), box(11), object(11), algorithm(8), map(7), step(5), shape(4), image(3), proposal(3), size(3)        An Introduction to Random Forest using the fastai Library (Machine Learning for Programmers &lt;U+2013&gt; Part 1)Keyword(freq): prediction(13), value(13), column(11), tree(11), point(10), row(9), model(8), sample(7), variable(6), feature(5)        Simplifying Data Preparation and Machine Learning Tasks using RapidMinerKeyword(freq): column(17), result(7), set(7), baye(5), model(5), change(4), flight(4), prediction(4), step(4), analytics(3)  Machine Learning Mastery NEWS TITLE      How to Load, Visualize, and Explore a Complex Multivariate Multistep Time Series Forecasting DatasetKeyword(freq): variable(95), chunk(50), observation(43), site(30), plot(24), model(17), value(15), column(10), row(10), time(10)        How to Develop LSTM Models for Multi-Step Time Series Forecasting of Household Power ConsumptionKeyword(freq): model(28), feature(16), step(15), input(13), unit(11), network(10), result(10), kilowatt(9), observation(9), time(8)        How to Develop Convolutional Neural Networks for Multi-Step Time Series ForecastingKeyword(freq): model(21), input(14), layer(13), step(12), variable(12), network(11), observation(10), result(10), feature(8), prediction(7)  ",
                  "url": "/newsletters/2018/10/13/newsletter.html"
                }
                ,
              
                "newsletters-2018-10-06-newsletter-html": {
                  "title": "2018.10.06. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Data Notes: Are Those Honey Bees Healthy?Keyword(freq): admission(1), bee(1), dataset(1), encoding(1), feature(1), framework(1), kernel(1), right(1), ring(1), trend(1)Data Camp NEWS TITLE  Full Stack Data Science (Transcript)Keyword(freq): project(9), scientist(8), client(6), company(6), environment(5), organization(5), skill(5), team(5), customer(4), econometric(4)Analytics Vidhya NEWS TITLE      5 Amazing Machine Learning GitHub Repositories &amp; Reddit Threads from September 2018Keyword(freq): repository(4), discussion(3), link(3), algorithm(2), code(2), comment(2), framework(2), pipeline(2), project(2), analytics(1)        DataHack Radio #11: Decision Intelligence with Google Cloud’s Chief Decision Scientist, Cassie KozyrkovKeyword(freq): project(4), entry(2), process(2), result(2), team(2), thought(2), appliance(1), application(1), augment(1), cassy(1)        Text Mining 101: A Stepwise Introduction to Topic Modeling using Latent Semantic Analysis (using Python)Keyword(freq): topic(19), document(10), term(6), concept(4), book(3), newsgroup(3), technique(3), cluster(2), dimension(2), librarian(2)         Text Mining 101: A Stepwise Introduction to Topic Modeling using Latent Semantic Analysis (using Python)Keyword(freq): topic(19), document(10), term(6), concept(4), book(3), newsgroup(3), technique(3), cluster(2), dimension(2), librarian(2)  Machine Learning Mastery NEWS TITLE      Multi-step Time Series Forecasting with Machine Learning for Household Electricity ConsumptionKeyword(freq): model(24), algorithm(18), observation(15), input(12), forecast(7), value(6), result(5), variable(5), output(4), score(4)        How to Develop an Autoregression Forecast Model for Household Electricity ConsumptionKeyword(freq): observation(17), model(12), plot(8), variable(7), time(6), value(6), step(5), forecast(4), kilowatt(4), correlation(3)        How to Develop and Evaluate Naive Methods for Forecasting Household Electricity ConsumptionKeyword(freq): model(13), strategy(11), score(7), observation(5), value(5), variable(5), method(4), implement(3), row(3), set(3)  ",
                  "url": "/newsletters/2018/10/06/newsletter.html"
                }
                ,
              
                "newsletters-2018-10-02-newsletter-html": {
                  "title": "2018.10.02. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  Full Stack Data Science (Transcript)Keyword(freq): project(9), scientist(8), client(6), company(6), environment(5), organization(5), skill(5), team(5), customer(4), econometric(4)Analytics Vidhya NEWS TITLE      Text Mining 101: A Stepwise Introduction to Topic Modeling using Latent Semantic Analysis (using Python)Keyword(freq): topic(19), document(10), term(6), concept(4), technique(4), book(3), newsgroup(3), cluster(2), dimension(2), librarian(2)        Building DataHack Summit 2018 &lt;U+2013&gt; India’s Most Advanced AI Conference. Are you Ready?Keyword(freq): session(6), price(2), auditorium(1), cake(1), corner(1), development(1), domain(1), event(1), hacker(1), highlight(1)        A Multivariate Time Series Guide to Forecasting and Modeling (with Python codes)Keyword(freq): value(19), variable(15), prediction(7), detail(3), equation(3), term(3), comment(2), method(2), result(2), set(2)        The Winning Approaches from codeFest 2018 &lt;U+2013&gt; NLP, Computer Vision and Machine Learning!Keyword(freq): hackathon(5), feature(3), approach(2), classifier(2), image(2), participant(2), scientist(2), tweet(2), analytics(1), answer(1)  Machine Learning Mastery NEWS TITLE      How to Develop and Evaluate Naive Methods for Forecasting Household Electricity ConsumptionKeyword(freq): model(13), strategy(11), score(7), observation(5), value(5), variable(5), implement(3), method(3), row(3), set(3)        How to Load and Explore Household Electricity Usage DataKeyword(freq): plot(15), method(13), variable(10), observation(9), example(6), value(6), feature(5), model(5), row(5), distribution(3)        Deep Learning Models for Human Activity RecognitionKeyword(freq): network(26), layer(25), model(19), activity(18), feature(18), window(16), method(11), sensor(9), cnn(8), problem(8)  ",
                  "url": "/newsletters/2018/10/02/newsletter.html"
                }
                ,
              
                "newsletters-2018-09-29-newsletter-html": {
                  "title": "2018.09.29. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE      What is Data Engineering?Keyword(freq): engineer(6), profession(2), scientist(2), type(2), algorithm(1), analysis(1), analyst(1), customer(1), example(1), format(1)        Uncertainty in Data Science (Transcript)Keyword(freq): prediction(20), time(14), question(8), simulation(8), algorithm(7), cdf(7), example(7), histogram(7), method(7), statistics(7)  Analytics Vidhya NEWS TITLE      Building DataHack Summit 2018 &lt;U+2013&gt; India’s Most Advanced AI Conference. Are you Ready?Keyword(freq): session(6), price(2), auditorium(1), cake(1), corner(1), development(1), domain(1), event(1), hacker(1), highlight(1)        A Multivariate Time Series Guide to Forecasting and Modeling (with Python codes)Keyword(freq): value(19), variable(12), prediction(7), detail(3), equation(3), term(3), comment(2), method(2), result(2), set(2)        The Winning Approaches from codeFest 2018 &lt;U+2013&gt; NLP, Computer Vision and Machine Learning!Keyword(freq): hackathon(4), feature(3), approach(2), classifier(2), image(2), participant(2), scientist(2), tweet(2), analytics(1), answer(1)        Reinforcement Learning Guide: Solving the Multi-Armed Bandit Problem from Scratch in PythonKeyword(freq): action(7), trial(7), algorithm(4), arm(4), case(3), result(3), reward(3), sample(3), strategy(3), work(3)        10 Mind-Blowing TED Talks on Artificial Intelligence Every Data Scientist &amp; Business Leader Must WatchKeyword(freq): talk(8), machine(4), algorithm(3), advance(2), car(2), leader(2), system(2), technique(2), algo(1), application(1)  Machine Learning Mastery NEWS TITLE      How to Load and Explore Household Electricity Usage DataKeyword(freq): plot(15), method(13), variable(10), observation(9), example(6), value(6), feature(5), model(5), row(5), distribution(3)        Deep Learning Models for Human Activity RecognitionKeyword(freq): network(26), layer(25), model(19), activity(18), feature(18), window(16), method(11), sensor(9), cnn(8), problem(8)        How to Develop RNN Models for Human Activity Recognition Time Series ClassificationKeyword(freq): feature(21), step(18), model(11), result(10), sequence(7), window(7), subsequence(6), time(6), activity(5), lstm(5)  ",
                  "url": "/newsletters/2018/09/29/newsletter.html"
                }
                ,
              
                "newsletters-2018-09-22-newsletter-html": {
                  "title": "2018.09.22. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE      Data Notes: How Do Autoencoders Work?Keyword(freq): autoencoder(2), convolution(2), case(1), channel(1), dataset(1), entity(1), kernel(1), media(1), model(1), number(1)        Help! I can’t reproduce a machine learning project!Keyword(freq): problem(10), result(10), package(8), file(6), difference(5), version(5), date(4), dataset(3), case(2), else(2)  Data Camp NEWS TITLE      New Skill Track: Tidyverse Fundamentals with RKeyword(freq): tool(5), plot(4), dataset(3), graphic(3), model(3), package(3), variable(3), factor(2), kaggle(2), price(2)        Becoming a Data Scientist (Transcript)Keyword(freq): scientist(19), question(14), skill(13), result(10), technique(10), path(9), resource(9), algorithm(8), job(8), basic(7)  Analytics Vidhya NEWS TITLE      Let’s Think in Graphs: Introduction to Graph Theory and its Applications using PythonKeyword(freq): graph(29), bridge(17), vertex(17), edge(10), node(9), concept(8), step(6), visualization(6), airport(5), tree(5)        Nuts &amp; Bolts of Reinforcement Learning: Model Based Planning using Dynamic ProgrammingKeyword(freq): state(16), algorithm(5), problem(4), action(3), equation(3), iteration(3), reward(3), bike(2), environment(2), episode(2)        DataHack Radio #10: The Role of Computer Science in the Data Science World with Dr. Jeannette M. WingKeyword(freq): method(7), mathematic(3), decade(2), technique(2), advantage(1), avanessian(1), concept(1), domain(1), episode(1), fan(1)  Machine Learning Mastery NEWS TITLE      How to Develop 1D Convolutional Neural Network Models for Human Activity RecognitionKeyword(freq): result(26), feature(19), map(11), step(10), model(8), sample(7), window(7), filter(6), activity(5), cnn(5)        How to Evaluate Machine Learning Algorithms for Human Activity RecognitionKeyword(freq): model(23), feature(17), method(13), result(13), algorithm(11), file(7), activity(6), tree(6), implement(5), sample(5)        How to Model Human Activity From Smartphone DataKeyword(freq): activity(46), subject(33), distribution(13), feature(11), plot(11), histogram(10), row(10), implement(9), smartphone(9), variable(9)  ",
                  "url": "/newsletters/2018/09/22/newsletter.html"
                }
                ,
              
                "newsletters-2018-09-15-newsletter-html": {
                  "title": "2018.09.15. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Winner Interview | Particle Tracking Challenge first runner-up, Pei-Lien ChouKeyword(freq): track(8), pair(5), hit(4), dot(3), bachelor(2), candidate(2), event(2), master(2), mathematic(2), method(2)Data Camp NEWS TITLE  Data Science at Stitch Fix (Transcript)Keyword(freq): machine(30), algorithm(29), clothe(22), client(13), decision(9), process(9), calculation(7), company(7), scientist(7), economic(6)Analytics Vidhya NEWS TITLE      Heroes of Deep Learning: Top Takeaways for Aspiring Data Scientists from Andrew Ng’s Interview SeriesKeyword(freq): expert(3), hero(3), gan(2), model(2), network(2), takeaway(2), topic(2), video(2), algorithm(1), ann(1)        How Machine Learning Algorithms &amp; Hardware Power Apple’s Latest Watch and iPhonesKeyword(freq): apple(4), sensor(4), algorithm(3), feature(3), product(3), core(2), operation(2), billion(1), company(1), contact(1)        A Gentle Introduction to Handling a Non-Stationary Time Series in PythonKeyword(freq): result(13), test(13), method(6), plot(4), property(4), interval(3), comment(2), model(2), observation(2), prediction(2)        Artificial Intelligence, Machine Learning and Big Data &lt;U+2013&gt; A Comprehensive ReportKeyword(freq): job(5), professional(3), analytics(2), change(2), company(2), engineer(2), industry(2), insight(2), opportunity(2), role(2)        Deep Learning Tutorial to Calculate the Screen Time of Actors in any Video (with Python codes)Keyword(freq): image(39), frame(10), prediction(6), model(5), step(5), result(4), video(4), feature(3), library(3), application(2)  Machine Learning Mastery NEWS TITLE      How to Develop a Reusable Framework to Spot-Check Algorithms in PythonKeyword(freq): algorithm(29), result(23), model(21), score(13), method(8), transform(8), problem(5), repeat(5), tree(5), configuration(4)        A Gentle Introduction to a Standard Human Activity Recognition ProblemKeyword(freq): activity(22), subject(17), window(15), observation(12), feature(10), plot(8), approach(7), duration(7), network(6), result(6)        Indoor Movement Time Series Classification with Machine Learning AlgorithmsKeyword(freq): room(17), observation(15), value(12), algorithm(10), dataset(10), feature(9), result(9), method(8), path(8), sequence(8)  ",
                  "url": "/newsletters/2018/09/15/newsletter.html"
                }
                ,
              
                "newsletters-2018-09-08-newsletter-html": {
                  "title": "2018.09.08. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Data Notes: The Secret to Getting to a Second DateKeyword(freq): model(3), analysis(1), dataset(1), date(1), explanation(1), feature(1), image(1), kernel(1), molecule(1), patent(1)Data Camp NEWS TITLE  Data Products, Dashboards, and Rapid Prototyping (Transcript)Keyword(freq): product(12), sport(10), question(8), dashboard(7), company(6), hour(4), industry(4), scientist(4), stakeholder(4), bioinformatic(3)Analytics Vidhya NEWS TITLE      An End-to-End Guide to Understand the Math behind XGBoostKeyword(freq): learner(16), residual(12), tree(11), model(6), technique(6), error(5), iteration(3), step(3), concept(2), feature(2)        The 5 Best Machine Learning GitHub Repositories &amp; Reddit Threads from August 2018Keyword(freq): notebook(4), comment(3), project(3), user(3), discussion(2), problem(2), repository(2), review(2), story(2), time(2)        DataHack Radio Episode #9: Data Science at Airbnb &amp; Lyft with Dr. Alok GuptaKeyword(freq): scientist(7), airbnb(3), mathematic(3), model(3), channel(2), employee(2), problem(2), service(2), algorithm(1), analytics(1)  Machine Learning Mastery NEWS TITLE      How to Develop a Probabilistic Forecasting Model to Predict Air Pollution DaysKeyword(freq): score(10), observation(8), model(7), tree(7), feature(6), variable(6), analysis(5), solution(5), forecast(4), method(4)        A Gentle Introduction to Probability Scoring Methods in PythonKeyword(freq): probability(26), prediction(16), value(13), model(5), example(4), forecast(4), score(4), threshold(4), argument(3), increment(3)        How and When to Use a Calibrated Classification Model with scikit-learnKeyword(freq): probability(55), prediction(12), diagram(8), model(7), algorithm(4), example(3), method(3), plot(3), result(3), svm(3)  ",
                  "url": "/newsletters/2018/09/08/newsletter.html"
                }
                ,
              
                "newsletters-2018-09-01-newsletter-html": {
                  "title": "2018.09.01. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  no new articleAnalytics Vidhya NEWS TITLE      Build High Performance Time Series Models using Auto ARIMA in Python and RKeyword(freq): value(10), technique(7), parameter(4), link(3), model(3), point(3), step(3), code(2), component(2), holt(2)        A Simple Introduction to Facial Recognition (with Python codes)Keyword(freq): face(8), image(8), feature(5), algorithm(4), celebrity(4), dimension(3), http(3), number(3), vector(3), application(2)        The Ultimate Guide to 12 Dimensionality Reduction Techniques (with Python codes)Keyword(freq): variable(55), component(23), value(22), feature(15), technique(13), image(10), point(10), dimension(8), factor(8), result(7)  Machine Learning Mastery NEWS TITLE      How and When to Use ROC Curves and Precision-Recall Curves for Classification in PythonKeyword(freq): curve(17), positive(15), negative(11), probability(11), value(10), threshold(6), measure(5), model(5), problem(5), score(5)        How to Predict Room Occupancy Based on Environmental FactorsKeyword(freq): file(6), measure(6), room(5), variable(5), model(4), observation(4), result(4), question(3), set(3), uci(3)        How to Predict Whether a Persons Eyes are Open or Closed Using Brain WavesKeyword(freq): observation(19), model(12), row(8), outlier(7), result(5), thank(5), deviation(4), method(4), peak(4), problem(3)  ",
                  "url": "/newsletters/2018/09/01/newsletter.html"
                }
                ,
              
                "kaggle-2018-08-31-kagglehomecredit2-html": {
                  "title": "(Kaggle Home Credit) top 1% with only 2 submissions? how?",
                  "author": "",
                  "category": "[&quot;Kaggle&quot;]",
                  "content": "learning from arnowaczynskihttps://www.kaggle.com/c/home-credit-default-risk/discussion/64609[[ 모델 블랜딩 전략 ]]      many CV runs with random seeds with different random split(10 folds)        simple average of top 30 models        ridge regression on top 60 models  [[ 하이퍼 파라미터 탐색 전략 ]]      num_boost_round = 10000 with early_stopping_rounds=200        bagging_freq = 1        tuning hyper-params(6):  learning_rate, num_leaves, max_depth, min_data_in_leaf, feature_fraction,  bagging_freq        random grid search        set discrete search space for each params        while searching, print every cv score with selected hyper-parameters        at any time, stop search and adjust the search space (make sure not same parames evaluated more than once)  ",
                  "url": "/kaggle/2018/08/31/kaggleHomecredit2.html"
                }
                ,
              
                "kaggle-2018-08-30-kagglesantander-html": {
                  "title": "Kaggle Santander Value Prediction TOP 8%",
                  "author": "",
                  "category": "[&quot;Kaggle&quot;]",
                  "content": "The digitalization of everyday lives means that customers expect services to be delivered in a personalized and timely manner… and often before they´ve even realized they need the service. In their 3rd Kaggle competition, Santander Group aims to go a step beyond recognizing that there is a need to provide a customer a financial service and intends to determine the amount or value of the customer’s transaction. This means anticipating customer needs in a more concrete, but also simple and personal way. With so many choices for financial services, this need is greater now than ever before.Santander Group is asking Kagglers to help them identify the value of transactions for each potential customer.[feature engineering]  leak features from kernel  statistical features (max, min, sd, median, avg)  na count features by row[modeling]  single light gbm  bayesian grid search  cv predict  boosting samples  cut range",
                  "url": "/kaggle/2018/08/30/kaggleSantander.html"
                }
                ,
              
                "kaggle-2018-08-30-kagglehomecredit-html": {
                  "title": "Kaggle Home Credit Default Risk TOP 6%",
                  "author": "",
                  "category": "[&quot;Kaggle&quot;]",
                  "content": "Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data–including telco and transactional information–to predict their clients’ repayment abilities.While Home Credit is currently using various statistical and machine learning methods to make these predictions, they’re challenging Kagglers to help them unlock the full potential of their data.[feature engineering]  collect many ideas from kernel  interaction features  indicator features[modeling]  many light gbm models with different dataset  bayesian grid search  cv predict  boosting samples  blend of base models",
                  "url": "/kaggle/2018/08/30/kaggleHomecredit.html"
                }
                ,
              
                "newsletters-2018-08-25-newsletter-html": {
                  "title": "2018.08.25. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE      Data Notes: Drought and the War in SyriaKeyword(freq): beginner(1), dataset(1), example(1), kernel(1), newsletter(1), package(1), right(1), statistics(1), tweet(1), NA(NA)        Getting Started with Competitions - A Peer to Peer GuideKeyword(freq): competition(8), other(7), file(6), model(6), scientist(6), variable(5), thousand(4), feature(3), kernel(3), project(3)  Data Camp NEWS TITLE  no new articleAnalytics Vidhya NEWS TITLE      The Ultimate Data Science and Machine Learning Blogathon &lt;U+2013&gt; More than $2500 up for grabs!Keyword(freq): analytics(6), article(6), fan(3), prize(2), standard(2), blogger(1), bonus(1), category(1), detail(1), draft(1)        A Hands-On Guide to Automated Feature Engineering using Featuretools in PythonKeyword(freq): feature(31), featuretool(14), sale(6), primitive(5), table(5), mark(4), title(4), variable(4), item(3), value(3)        A Practical Introduction to K-Nearest Neighbors Algorithm for Regression (with Python code)Keyword(freq): point(11), value(10), algorithm(3), problem(3), article(2), feature(2), method(2), prediction(2), question(2), sale(2)        Launching Analytics Vidhya’s Medium Publication and AV Editor’s club!Keyword(freq): benefit(3), analytics(2), creator(1), editor(1), effort(1), framework(1), idea(1), meetup(1), point(1), professional(1)        DataHack Radio Episode #8: How Self-Driving Cars Work with Drive.ai’s Brody HuvalKeyword(freq): car(9), approach(2), camera(2), lane(2), network(2), object(2), project(2), sensor(2), street(2), technique(2)  Machine Learning Mastery NEWS TITLE      How to Model Volatility with ARCH and GARCH for Time Series Forecasting in PythonKeyword(freq): model(9), change(5), error(5), step(5), variance(4), parameter(3), plot(3), value(3), example(2), increase(2)        4 Common Machine Learning Data Transforms for Time Series ForecastingKeyword(freq): transform(11), value(9), operation(6), coefficient(5), prediction(5), method(4), result(4), algorithm(2), comment(2), estimate(2)        A Gentle Introduction to Exponential Smoothing for Time Series Forecasting in PythonKeyword(freq): method(9), observation(9), forecast(6), principle(6), statsmodel(6), coefficient(5), value(5), parameter(4), thank(4), hyperparameter(3)  ",
                  "url": "/newsletters/2018/08/25/newsletter.html"
                }
                ,
              
                "newsletters-2018-08-18-newsletter-html": {
                  "title": "2018.08.18. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  no new articleAnalytics Vidhya NEWS TITLE      Top 7 Sectors where Data Science can Transform India (with Free Datasets)Keyword(freq): dataset(14), accident(5), hospital(3), indian(3), jam(3), level(3), pattern(3), point(3), resource(3), sector(3)        DataHack Radio Episode #7: Tackling Data Science Challenges in India with NITI Aayog’s Dr. Avik Sarkar (Independence Day Special!)Keyword(freq): challenge(5), article(3), avik(3), master(3), statistics(3), topic(3), analytics(2), india(2), indian(2), insight(2)        Complete tutorial on Text Classification using Conditional Random Fields Model (in Python)Keyword(freq): feature(6), entity(4), claim(3), analytics(2), email(2), example(2), pattern(2), problem(2), sequence(2), thank(2)  Machine Learning Mastery NEWS TITLE      A Gentle Introduction to SARIMA for Time Series Forecasting in PythonKeyword(freq): element(8), hyperparameter(5), parameter(5), step(4), term(4), plot(3), variable(3), argument(2), model(2), question(2)        15 Statistical Hypothesis Tests in Python (Cheat Sheet)Keyword(freq): test(26), assumption(17), sample(15), distribution(4), mean(4), question(4), answer(3), list(3), result(3), thank(3)        How to Reduce Variance in a Final Machine Learning ModelKeyword(freq): model(15), prediction(15), parameter(6), approach(4), decision(3), estimate(3), example(3), sample(3), source(3), term(3)  ",
                  "url": "/newsletters/2018/08/18/newsletter.html"
                }
                ,
              
                "newsletters-2018-08-11-newsletter-html": {
                  "title": "2018.08.11. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Data Notes: From Hate Speech to Russian Troll TweetsKeyword(freq): tweet(2), building(1), dataset(1), election(1), image(1), kernel(1), right(1), statistics(1), trend(1), NA(NA)Data Camp NEWS TITLE  no new articleAnalytics Vidhya NEWS TITLE      Independence Day Bonanza with Analytics Vidhya’s Offers and Launches!Keyword(freq): sector(2), analytics(1), challenge(1), conference(1), dataset(1), deal(1), government(1), kick(1), leader(1), link(1)        Ultimate guide to handle Big Datasets for Machine Learning using Dask (in Python)Keyword(freq): panda(17), array(14), machine(10), computation(9), core(9), parameter(9), dataset(8), library(8), task(8), value(8)        Infographic &lt;U+2013&gt; A Complete Guide on Getting Started with Deep Learning in PythonKeyword(freq): innovation(1), resource(1), NA(NA), NA(NA), NA(NA), NA(NA), NA(NA), NA(NA), NA(NA), NA(NA)        DataHack Radio Episode #6: Exploring Techniques and Strategy with Coursera’s Head of Data Science, Emily Glassberg SandsKeyword(freq): coursera(6), learner(6), certificate(4), model(4), economic(3), market(3), point(3), technique(3), user(3), folk(2)  Machine Learning Mastery NEWS TITLE      How to Develop a Skillful Machine Learning Time Series Forecasting ModelKeyword(freq): model(9), result(8), method(7), question(4), resource(4), scheme(4), configuration(3), experiment(3), answer(2), approach(2)        Taxonomy of Time Series Forecasting ProblemsKeyword(freq): variable(17), observation(13), question(9), input(5), output(5), answer(4), problem(4), step(3), comment(2), constraint(2)        11 Classical Time Series Forecasting Methods in Python (Cheat Sheet)Keyword(freq): model(27), method(15), component(11), observation(11), step(10), variable(10), thank(8), parameter(7), comment(5), error(5)  ",
                  "url": "/newsletters/2018/08/11/newsletter.html"
                }
                ,
              
                "newsletters-2018-08-04-newsletter-html": {
                  "title": "2018.08.04. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE  Pharmaceuticals and Data Science (Transcript)Keyword(freq): data(82), statistics(13), compound(12), scientist(11), problem(10), experiment(8), statisticsian(8), time(8), type(8), number(5)Analytics Vidhya NEWS TITLE      The Best Machine Learning GitHub Repositories &amp; Reddit Threads from July 2018Keyword(freq): data(7), link(4), repository(4), resource(4), discussion(3), expert(3), gan(3), model(3), scientist(3), concept(2)        Comprehensive Hands on Guide to Twitter Sentiment Analysis with dataset and codeKeyword(freq): data(29), tweet(29), feature(13), term(11), hashtag(9), token(7), character(4), model(4), number(4), sentiment(4)  Machine Learning Mastery NEWS TITLE      Why Initialize a Neural Network with Random Weights?Keyword(freq): weight(17), algorithm(14), network(5), data(4), kera(4), number(4), problem(4), unit(4), dollare(3), input(3)        How to Code the Student’s t-Test from Scratch in PythonKeyword(freq): sample(33), student(15), mean(14), observation(6), degree(5), result(5), test(5), data(4), difference(4), function(4)  ",
                  "url": "/newsletters/2018/08/04/newsletter.html"
                }
                ,
              
                "newsletters-2018-07-28-newsletter-html": {
                  "title": "2018.07.28. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Data Notes: Winning Solutions of Kaggle CompetitionsKeyword(freq): avocado(2), app(1), competition(1), dataset(1), data(1), image(1), kernel(1), method(1), price(1), principle(1)Data Camp NEWS TITLE      New Project: Visualizing Inequalities in Life ExpectancyKeyword(freq): data(2), man(2), woman(2), expectancy(1), nation(1), period(1), question(1), NA(NA), NA(NA), NA(NA)        Data Science at Doctors without Borders (Transcript)Keyword(freq): data(79), village(18), survey(14), doctor(11), net(11), result(10), border(9), question(9), project(7), term(5)        Chatbots, Conversational Software &amp; Data Science (Transcript)Keyword(freq): conversation(15), data(14), chatbot(13), library(11), case(10), rule(9), question(8), company(7), developer(6), industry(6)  Analytics Vidhya NEWS TITLE      Top 10 Pretrained Models to get you Started with Deep Learning (Part 1 &lt;U+2013&gt; Computer Vision)Keyword(freq): image(13), model(10), application(7), kera(5), weight(4), caption(3), car(3), object(3), tomato(3), article(2)        Infographic &lt;U+2013&gt; 13 Common Mistakes Amateur Data Scientists Make and How to Avoid ThemKeyword(freq): data(4), scientist(3), mistake(2), resource(2), challenge(1), effort(1), expert(1), list(1), tip(1), trap(1)        Top Highlights from AV’s Record-Breaking Weekend Online HackathonKeyword(freq): analytics(4), participant(3), agent(2), data(2), hackathon(2), policy(2), approach(1), comment(1), criterion(1), demographic(1)        DataHack Radio Episode #5: Building High Performance Data Science teams with Kiran RKeyword(freq): data(21), competition(6), model(6), technique(5), analytics(4), kiran(4), problem(4), platform(3), science(3), skill(3)  Machine Learning Mastery NEWS TITLE      How to Configure the Number of Layers and Nodes in a Neural NetworkKeyword(freq): layer(28), node(20), network(12), function(7), problem(7), variable(6), hyperparameter(4), idea(4), input(4), output(4)        How to Calculate McNemar’s Test to Compare Two Machine Learning ClassifiersKeyword(freq): model(19), mcnemar(16), test(11), classifier(9), result(8), algorithm(7), case(7), cell(6), method(5), data(4)        When to Use MLP, CNN, and RNN Neural NetworksKeyword(freq): network(21), data(17), problem(14), type(9), layer(6), model(6), rnn(6), cnn(5), input(5), detail(4)  ",
                  "url": "/newsletters/2018/07/28/newsletter.html"
                }
                ,
              
                "newsletters-2018-07-21-newsletter-html": {
                  "title": "2018.07.21. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  no new articleData Camp NEWS TITLE      New Project: Naive Bees: Image Loading and ProcessingKeyword(freq): data(5), image(2), classifier(1), prerequisite(1), project(1), researcher(1), species(1), technique(1), transformation(1), NA(NA)        Data Science at McKinsey (Transcript)Keyword(freq): data(96), analytics(45), tara(33), model(29), decision(16), organization(16), scientist(13), client(10), industry(9), algorithm(8)  Analytics Vidhya NEWS TITLE      FLASH SALE! Get Flat 55% off on our Popular ‘Introduction to Data Science’ Course!Keyword(freq): data(6), project(3), agent(2), product(2), sale(2), scientist(2), analytics(1), aspect(1), attribute(1), basic(1)        Ultimate Guide: Building a Mask R-CNN Model for Detecting Car Damage (with Python codes)Keyword(freq): image(7), annotation(4), application(3), car(3), model(3), pixel(3), weight(3), error(2), example(2), layer(2)        MyStory: Step by Step process of How I Became a Machine Learning Expert in 10 MonthsKeyword(freq): data(17), topic(11), algorithm(5), skill(5), concept(4), model(4), step(4), detail(3), parameter(3), run(3)        An Introductory Guide to Maximum Likelihood Estimation (with a case study in R)Keyword(freq): data(21), parameter(14), coefficient(9), ticket(8), distribution(6), observation(4), bfg(3), problem(3), result(3), technique(3)  Machine Learning Mastery NEWS TITLE      What is the Difference Between a Batch and an Epoch in a Neural Network?Keyword(freq): sample(18), epoch(17), parameter(12), batch(10), thank(8), algorithm(6), prediction(6), value(5), network(4), data(3)        The Role of Randomization to Address Confounding Variables in Machine LearningKeyword(freq): variable(34), experiment(8), data(6), effect(5), method(5), model(5), result(5), experimenter(4), confounder(3), example(3)        All of Statistics for Machine LearningKeyword(freq): statistics(27), topic(10), data(5), example(4), method(4), comment(3), practitioner(3), student(3), algorithm(2), developer(2)  ",
                  "url": "/newsletters/2018/07/21/newsletter.html"
                }
                ,
              
                "newsletters-2018-07-17-newsletter-html": {
                  "title": "2018.07.17. 데이터 사이언스 뉴스레터",
                  "author": "",
                  "category": "newsletters",
                  "content": "데이터 사이언스 뉴스레터 (wordcloud)Kaggle Blog NEWS TITLE  Data Notes: How to Forecast the S&amp;P 500 with ProphetKeyword(freq): data(3), party(2), car(1), celebface(1), dataset(1), extraterrestrial(1), kernel(1), market(1), method(1), pca(1)Data Camp NEWS TITLE  Data Science at McKinsey (Transcript)Keyword(freq): data(96), analytics(45), tara(33), model(29), decision(16), organization(16), scientist(13), client(10), industry(9), algorithm(8)Analytics Vidhya NEWS TITLE      An Introductory Guide to Maximum Likelihood Estimation (with a case study in R)Keyword(freq): data(24), parameter(15), coefficient(10), ticket(8), variable(7), distribution(6), observation(4), result(4), bfg(3), problem(3)        13 Common Mistakes Amateur Data Scientists Make and How to Avoid Them?Keyword(freq): data(44), scientist(13), tool(7), competition(6), technique(6), model(5), problem(5), resource(5), thank(5), skill(4)  Machine Learning Mastery NEWS TITLE      The Role of Randomization to Address Confounding Variables in Machine LearningKeyword(freq): variable(32), experiment(8), data(6), effect(5), method(5), model(5), result(5), experimenter(4), confounder(3), example(3)        All of Statistics for Machine LearningKeyword(freq): statistics(27), topic(10), data(5), example(4), method(4), comment(3), practitioner(3), student(3), algorithm(2), developer(2)        A Gentle Introduction to Statistical Power and Power Analysis in PythonKeyword(freq): sample(10), curve(7), parameter(7), result(7), observation(5), size(5), student(5), analysis(4), variable(4), axi(3)  ",
                  "url": "/newsletters/2018/07/17/newsletter.html"
                }
                ,
              
                "kaggle-2018-07-10-kaggletitanic-html": {
                  "title": "Kaggle Titanic Machine Learning from Disaster TOP 3%",
                  "author": "",
                  "category": "[&quot;Kaggle&quot;]",
                  "content": "캐글(Kaggle)은 전세계에서 가장 큰 데이터 분석 경진 대회입니다.https://www.kaggle.com/  캐글은 2010년 설립된 예측모델 및 분석 대회 플랫폼이다. 기업 및 단체에서 데이터와 해결과제를 등록하면, 데이터 과학자들이 이를 해결하는 모델을 개발하고 경쟁한다. 2017년 3월 구글에 인수되었다. (위키피디아)Titanic Competition 소개Titanic Competition은 데이터 분석 입문자들을 위한 캐글 데이터 분석 대회입니다.Titanic Competition은 1912년 4월 15일 타이타닉 침몰 사고의 실제 데이터 입니다.데이터셋에는 객실 등급, 나이, 성별, 항만, 티켓번호 이름 등의 정보가 있고 이를 사용해서 승객의 생존을 예측하는 경진 대회입니다.DS랩도 Titanic Competition에 참여헸고 결과는 다음과 같습니다.사용한 머신러닝 알고리즘Titanic Competition 경진대회에서 사용한 분석 방법은 다음과 같습니다. (RANK TOP 3%)  사용한 머신러닝 알고리즘 : CatBoost, H2O XGBoost, H2O Light GBM  CatBoost, (H2O) XGBoost, (H2O) Light GBM in R and Python 모델 튜닝 코드 (https://github.com/2econsulting/Kaggle)            file name      accuracy      threshold                  R_TEST_CATBOOST_TUNE_P1.csv      0.82296      &gt;0.5              R_TEST_CATBOOST_TUNE_CVP1.csv      0.81818      &gt;0.5              R_TEST_H2OXGB_TUNE_CVP1.csv      0.81339      &gt;0.5              R_TEST_CATBOOST_TUNE_CVP1_78.csv      0.81339      &gt;0.5              R_TEST_H2OLGB_TUNE_CVP1.csv      0.81818      &gt;0.5      단일 모델로는 CatBoot의 0.82296(AUC)으로 가장 높았습니다.CatBoost, H2O XGBoost, H2O Light GBM의 예측값을 다수결 방식으로 결합한 Stacking 모델은 0.83253(AUC)을 얻었습니다.",
                  "url": "/kaggle/2018/07/10/kaggleTitanic.html"
                }
                ,
              
                "featuretools-python-2018-06-29-featuretools-html": {
                  "title": "Featuretools(automating feature engineering) in Python",
                  "author": "",
                  "category": "[&quot;Featuretools&quot;, &quot;Python&quot;]",
                  "content": "연구 중, 업로드 예정일 2018년 9월 30일",
                  "url": "/featuretools/python/2018/06/29/featuretools.html"
                }
                ,
              
                "lightgbm-2018-06-25-gbm-vs-lightgbm-html": {
                  "title": "Light GBM in R and Python (GBM vs Light GBM)",
                  "author": "",
                  "category": "LightGBM",
                  "content": "Light GBM은 2014년 3월에 나온 XGBoost 알고리즘 이후, 2017년 1월에 발표된 알고리즘이다. GBM은 가지가 1번 분리될 때 2개씩 매번 분리가 되서 overfitting이 잘 일어난다. 하지만 LightGBM은 가지가 1번 분리(2개의 node 생성)될 때  모든 가지를 분리하지 않고 2개의 node 중 잘 맞는 node 기준으로만 나눈다. 전체적인 아키텍처는 다음과 같다.Light GBM 구조XGBoost 구조XGBoost와 GBM은 둘 다 위와 같은 구조로 되어 있다. 따라서 node가 많이 생기므로, 모델이 더 복잡해진다. 복잡해진 모델은 overfitting을 야기하기 쉽다. 반면, LightGBM은 그림과 같이 node가 비교적 적게 생긴다. 따라서 GBM이나 XGBoost보다 overfitting이 일어날 확률이 더 적어진다.본 포스팅에서는 R과 Python 각각 GBM과 Light GBM을 비교해본다. 데이터는 “churn” 데이터이고 출처는 데이터 출처(Github) 이다. 현재 H2O로 Light GBM 모델링은 XGBoost에 parameter를 조정해서 사용한다. 하지만 현재 XGBoost 모듈은 Windows 에는 지원을 하지 않으니, 아래에 있는 코드를 돌리기 위해서는 Mac OS 나 linux 등 Windows 이외의 환경에서 실행을 해야 한다.성능비교 (GBM vs Light GBM in R &amp; Python)            model      time(sec)      AUC      Logloss                  H2O GBM in python      0.98      0.9118      0.1954              H2O Light GBM in python      2.31      0.9234      0.1694              H2O GBM in R      2.85      0.9118      0.1954              H2O Light GBM in R      3.91      0.9234      0.1694      전체 분석 코드  GBM vs Light GBM in R  GBM vs Light GBM in Python",
                  "url": "/lightgbm/2018/06/25/GBM_vs_LightGBM.html"
                }
                ,
              
                "catboost-2018-06-17-tuningcatboost-html": {
                  "title": "CatBoost 튜닝 in R (using caret패키지)",
                  "author": "",
                  "category": "CatBoost",
                  "content": "caret패키지를 사용한 CatBoost 튜닝 v0.01 (random grid search)# library library(catboost)library(caret)library(titanic)# load datadata &lt;- as.data.frame(as.matrix(titanic::titanic_train), stringsAsFactors=TRUE)# handle missing valueage_levels &lt;- levels(data$Age)most_frequent_age &lt;- which.max(table(data$Age))data$Age[is.na(data$Age)] &lt;- age_levels[most_frequent_age]# set x and y drop_columns = c(\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\")x &lt;- data[,!(names(data) %in% drop_columns)]y &lt;- data[,c(\"Survived\")]# use caret for grid search fit_control &lt;- caret::trainControl(  method = \"cv\",   number = 3,   search = \"random\",  classProbs = TRUE)# set grid optionsgrid &lt;- expand.grid(  depth = c(4, 6, 8),  learning_rate = 0.1,  l2_leaf_reg = 0.1,  rsm = 0.95,  border_count = 64,  iterations = 10)# train catboostmodel &lt;- caret::train(  x = x,   y = as.factor(make.names(y)),  method = catboost.caret,  metric = \"Accuracy\",  maximize = TRUE,  preProc = NULL,  tuneGrid = grid,   tuneLength = 30,   trControl = fit_control)print(model)# variable importanceimportance &lt;- varImp(model, scale = FALSE)print(importance)",
                  "url": "/catboost/2018/06/17/tuningCatBoost.html"
                }
                ,
              
                "catboost-2018-06-16-catboostsimpleversion-html": {
                  "title": "CatBoost in R &amp; Python (simple version)",
                  "author": "",
                  "category": "CatBoost",
                  "content": "새로운 머신러닝 알고리즘 CatBoost가 등장했습니다. 러시아 과학자가 개발한 CatBoost는 Tree Boosting 계열의 최신 머신러닝 알고리즘 입니다. 최근 들어 Tree Boosting 계열의 머신러닝 알고리즘이 활발하게 연구되고 있습니다. 이는 아마도 XGBoost가 캐글 대회에서 수차례 winning solution으로 검증되면서 많은 과학자들이 XGBoost와 같은 Tree Boosting 머신러닝 기법에 많은 관심을 갖고 있는 것 같습니다.Tree Boosting 머신러닝 변천사CatBoost의 장점특히 CatBoost의 full name은 Categorical Boost으로 범주형 변수가 많은 데이터셋에서 예측 성능이 우수하다고 합니다. link  높은 예측 성능  범주형 변수를 자동으로 전처리  모델 튜닝이 간소화 (범주형 변수를 자동으로 전처리 해주니깐 그 부분에 대해서 따로 튜닝을 할 필요x)  R 그리고 Python과 연동CatBoost의 장점 (추가)  CatBoost 개발자에 의하면 모델 튜닝 없이 default값으로만 좋은 성능을 보여준다고 합니다. 또한 튜닝을 통해서 얻을 수 있는 효과는 크지 않다고 합니다. link  CatBoost gives great results with default values of the training parameters. In most cases parameter tuning does not significantly affect the resulting quality of the model and therefore is unnecessary. However, CatBoost provides a very flexible interface for parameter tuning and can be configured to suit different tasks.성능비교 (RF vs GBM vs CatBoost)Tree기반의 대표적인 머신러닝 알고리즘에는 Random Forest(RF)와 Gradient Boosting Machine(GBM)이 존재합니다. CatBoost가 RF와 GBM과 비교해서 속도 및 예측 성능의 차이를 비교하였습니다.            model      time(sec)      AUC      Logloss                  H2ORF in Python      0.73      0.9153      0.3039              H2OGBM in Python      0.49      0.9118      0.1954              CatBoost in Python      22.50      0.9539      0.1148              H2ORF in R      1.57      0.9170      0.3607              H2OGBM in R      1.69      0.9160      0.1931              CatBoost in R      29.73      0.9259      0.1565      CatBoost 설치 방법 및 전체 분석 코드  CatBoost in Python  CatBoost in R",
                  "url": "/catboost/2018/06/16/catboostSimpleVersion.html"
                }
                ,
              
                "recommendersystem-2018-06-14-recommendersystem-html": {
                  "title": "추천 시스템 R패키지 비교 연구",
                  "author": "",
                  "category": "recommenderSystem",
                  "content": "추천 R패키지 속도 및 성능 비교 연구 결과입니다.  데이터셋 : MovieLense (100만행)  컴퓨터 사양 : 7i, 32Gb RAM패키지 목록            package name      package description                  Myrrix      Real-Time, Scalable Clustering and Recommender System, Evolved from Apache Mahout              recommenderlab      Lab for Developing and Testing Recommender Algorithms              recosystem      Recommender System using Matrix Factorization              rrecsys      Environment for Evaluating Recommender Systems              slimrec      Sparse Linear Method to Predict Ratings and Top-N Recommendations      패키지 성능 비교            package name      algorithm      time(min)      RMSE                  recommenderlab      Most Popular      4.27      0.9725                     User-Based CF      5.03      1.0464                     Item-based CF      7.11      1.5074                     SVD      5.52      1.0204                     Funk SVD      13.91      0.9106                     Random      3.49      1.3832                     ALS      13.14      0.9032              rrecsys      itemAverage      7.37      0.9614                     userAverage      6.95      1.0140                     globalAverage      6.22      1.0913                     IBKNN      7.53      1.0853                     UBKNN      37.49      1.0196                     FunkSVD      31.36      1.0811                     SlopeOne      15.48      0.9028              recosystem      Matrix Factorization      0.68      0.8529              slimrec      Sparse Linear Method      25.52      2.2196              SVDApproximation      SVDApproximation      4.92      0.9313              SmartCat-labs’s Git R code      ibcf      1.76      0.8859                     ubcf      1.74      0.8564      전체 분석 코드  Comparison of Recommend system packages in R",
                  "url": "/recommendersystem/2018/06/14/recommenderSystem.html"
                }
                ,
              
                "catboost-2018-06-14-catboost-html": {
                  "title": "CatBoost in R &amp; Python (detail)",
                  "author": "",
                  "category": "CatBoost",
                  "content": "Yandex 가 2017년 6월에 논문 CatBoost: unbiased boosting with categorical features에서 소개한 방법이다. CatBoost는 “Categorical Boost” 약자로, 이름에서부터 범주형 변수를 위한 Boosting 방법이라는 냄새를 풍기고 있다.저자는 기존에 범주형 변수를 변환했던 방법 중에, “Target mean encoding”로 하면 정보유출(target leakage)이 생긴다고 주장한다. Target mean encoding이란, 범주별로 target 비율을 구해 해당 값으로 대체하는 것이다. 예를 들어, X 변수에 {A, A, A, B, B}가 있고, Target이 {1, 0, 0, 1, 0}이면, A 범주에서 Target 비율은 0.3333, B 범주에서 Target 비율은 0.5 이므로, {0.3333, 0.3333, 0.3333, 0.5, 0.5}로 변환이 된다. 또한, 정보유출로 인해 “conditional shift”가 발생하는데, 다시말해서 train 데이터와 test 데이터가 다른 분포를 가진다는 것이다. 서로 다른 분포를 가진다면, train 데이터에서 학습 된 모형이 test 데이터에 잘 맞기가 힘들 것이다. 개선방안으로 다음 2 step을 제안한다.  Ordered TBS(Target-Based Statistics)  Ordered boosting먼저, Ordered TBS에 대해서 알아보자. 흥미로운 아이디어는, 변환하기 전에 데이터를 랜덤하게 섞는다는 것이다. 섞은 데이터에서 다음 식을 이용해 변환을 한다.여기서 대괄호([]) 의미는, 랜덤하게 재배치한 후 위에서부터 차례로 내려오면서 계산을 한다고 생각하면 된다. 이런 수식을 말로만 풀면 어려우니, Yandex 홈페이지에 있는 변환 예시를 보면서 설명한다.위에 예시에서 이 우리가 최종적으로 변환해야 할 범주형 변수이고, 데이터는 한번 랜덤으로 재배치가 끝난 상태이다. 간단하게 만들기 위해  로 놓고 다음과 같이 바꿔보자.       : 현재 행에 있는 범주 기준으로 이전까지 target ‘1’(or True) 갯수         : 미리 지정. (예시에서는 0.05)         : 현재 행에 있는 범주 기준으로 이전까지 해당 범주 갯수  이를 반영하면 아래와 같이 변경된다. 아래에 행마다 설명을 달아놓았으니 참고해서 이해하면 더 쉬울거라 생각한다.설명  rock : 처음등장. 0.05  indie : 처음증장. 0.05  rock :  (rock 기준 이전에 target = 0번, rock = 1번 등장)  rock  :  (rock 기준 이전에 target = 1번, rock = 2번 등장)  pop : 처음등장. 0.05  indie :  (indie 기준 이전에 target = 0번, indie = 1번 등장)  rock :  (rock 기준 이전에 target = 2번, rock = 3번 등장)후에 설명드릴 내용은, Ordered Boosting에 대한 내용이다. 이는 overfitting 을 방지하기 위한 방법으로 다소 복잡해 본 포스팅에서는 간단한 개념만 설명한다. 기존 Boosting 방법은 만약 번째 tree를 나누었다면 나눈 후에 오차를 계산해 가중치 업데이트를 했다. 하지만 이렇게 오차를 구하면 편향이 발생돼 train 데이터에만 잘 맞을 수 있다는 단점이 있다(overfitting). 왜냐하면 번 째 tree를 나눴을 때의 오차가 train과 test에서 같다고 볼 수 없기 때문이다. 따라서 저자는 논문에서, 학습시에 번 째 관측치는 제외한 까지의 관측으로 오차를 구해 “불편 잔차(unbiased residual)”를 구하고 가중치를 업데이트해야 overfitting을 방지할 수 있다고 주장한다.논문의 핵심 주제인 Ordered TBS와 Ordered Boosting에 대해서 간단히 알아보았다.장단점장점으로는, 범주형 변수를 변환할 때 기존 방법대비 정보유출을 덜 했다는 점이다. 어쨋든 target을 가지고 변환을 했기 때문에 정보유출이 아예 되지 않았다고 하기는 곤란하다. 하지만 순열로 데이터의 배열을 재배치한 후 인코딩 작업을 여러번 반복하면서 변환을 했다는 점이 흥미롭고 충분한 장점이 된다고 생각한다. 다만, 데이터가 n개가 있을 시 순열로 가능한 경우의 수는 (n factorial)이다. n이 100만 되어도,  이라는 어마어마한 경우의 수가 나온다. encoding을 할 때 배열된 순서에 따라 달라지기 때문에, 과연 경우의수를 몇번 뽑아서 학습을 해야 괜찮은지에 대한 기준이 애매하다는 점이 단점이다.실제 샘플데이터(Churn)로 CatBoost, Random Forest, GBM을 비교 결과 CatBoost가 속도가 상당히 느렸다. 전부 default로 된 parameter를 이용했는데, CatBoost는 20초대, 다른 2개는 1초 근방으로 거의 20배 차이가 난다. 이는 CatBoost가 default iteration이 1000번으로 설정 되어있기 때문이다. 경우의 수가 워낙 방대하기 때문에, 어느정도 많이 돌려야 결과를 신뢰할 수 있다. 따라서 일부러 큰 숫자로 설정한 것으로 추정된다. 자세한 코드 및 설명은 맨 아래 링크에 첨부되어 있다.Python      설치 방법    pip install catboost        학습 (예측성능, 속도) 비교 (아래 Jupyter notebook 첨부)    CatBoost in Python  R  설치방법          아래 Jupyter notebook 참고            학습 (예측성능, 속도) 비교 (아래 Jupyter notebook 첨부)    CatBoost in R  ",
                  "url": "/catboost/2018/06/14/catboost.html"
                }
                ,
              
                "gridsearch-2018-06-14-bayesiangridsearch-html": {
                  "title": "Bayesian Optimization using R and H2O",
                  "author": "",
                  "category": "gridSearch",
                  "content": "rBayesianOptimization을 사용한 h2o.gbm 튜닝 코드입니다. 모델 튜닝은 최적의 하이퍼 파라미터를 찾는 행위이고 이를 grid search라고 합니다.가장 많이 사용되고 있는 grid search 방법으로는 모든 가능한 경우를 테스트하는 Cartesian grid search방법과, 모든 가능한 경우 중 일부를 랜덤하게 선택하여 테스트하는 Random grid search방법이 존재합니다.Bayesian grid search방법은 기존의 Random, Cartesian방법 보다 더 고급진 grid search방법입니다.  Bayesian Optimization helped us find a hyperparameter configuration that is better than the one found by Random Search for a neural network on the San Francisco Crimes dataset. linkBayesian grid search의 특징은 최적의 하이퍼 파라미터를 찾는데 이전의 탐색 결과를 참고합니다. 이전에 탐색 결과를 다음 탐색에 참고하기 때문에 랜덤하게 탐색하는 것보다 더 효율적이라고 말할 수 있습니다.# bayesGridFunbayesGridFun &lt;- function(max_depth, min_rows, sample_rate, col_sample_rate){  gbm &lt;- h2o.gbm(    x = x, y = y, seed = 1234,    training_frame = h2o.rbind(train_hex, valid_hex),    nfolds = 3,    score_each_iteration = TRUE,    stopping_metric = \"logloss\",    ntrees = 10000,    stopping_rounds = autoGBM_BestParams$stopping_rounds,    stopping_tolerance = autoGBM_BestParams$stopping_tolerance,    categorical_encoding = autoGBM_BestParams$Random_categorical_encoding,    learn_rate = autoGBM_BestParams$Random_learn_rate,    max_depth = max_depth,    min_rows = min_rows,    sample_rate = sample_rate,    col_sample_rate = col_sample_rate  )  score &lt;- h2o.auc(gbm, xval = T)  list(Score = score, Pred  = 0)}# bayesGridOptionsmax_depth &lt;- autoGBM_BestParams$Random_max_depthsample_rate &lt;- autoGBM_BestParams$Random_sample_ratecol_sample_rate &lt;- autoGBM_BestParams$Random_col_sample_ratemin_rows &lt;- autoGBM_BestParams$Random_min_rowsbayesGridOptions &lt;- list(  max_depth = as.integer(c(max(2, max_depth-1), max_depth+1)),  min_rows  = as.integer(c(max(1, min_rows-5), min_rows+5)),  sample_rate = c(sample_rate-0.1, min(sample_rate+0.1, 1)),  col_sample_rate = c(col_sample_rate-0.1, min(col_sample_rate+0.1, 1)))# bayesGridSearchset.seed(1234)bayesGridSearch &lt;- rBayesianOptimization::BayesianOptimization(  FUN = bayesGridFun,  bounds = bayesGridOptions,  init_points = init_points,  n_iter = n_iter,  acq = \"ucb\",  kappa = 2.576,  eps = 0.0,  verbose = TRUE)# H2OGBM_BayesianH2OGBM_Bayesian &lt;- h2o.gbm(  x = x, y = y, seed = 1234,  model_id = \"H2OGBM_Bayesian\",  training_frame = train_hex,  validation_frame = valid_hex,  score_each_iteration = TRUE,  stopping_metric = \"logloss\",  ntrees = 10000,  stopping_rounds = autoGBM_BestParams$stopping_rounds,  stopping_tolerance = autoGBM_BestParams$stopping_tolerance,  categorical_encoding = autoGBM_BestParams$Random_categorical_encoding,  learn_rate = autoGBM_BestParams$Random_learn_rate,  max_depth = as.numeric(bayesGridSearch$Best_Par[\"max_depth\"]),  min_rows = as.numeric(bayesGridSearch$Best_Par[\"min_rows\"]),  sample_rate = as.numeric(bayesGridSearch$Best_Par[\"sample_rate\"]),  col_sample_rate = as.numeric(bayesGridSearch$Best_Par[\"col_sample_rate\"]))autoGBM_Models[\"H2OGBM_Bayesian\"] &lt;- list(h2o.getModel(\"H2OGBM_Bayesian\"))h2o.auc(h2o.performance(autoGBM_Models[\"H2OGBM_Bayesian\"][[1]], newdata = test_hex))saveRDS(autoGBM_Models['H2OGBM_Bayesian'], file.path(model_path, \"H2OGBM_Bayesian.rda\"))autoGBM_BestParams['Bayes_max_depth'] &lt;- as.numeric(bayesGridSearch$Best_Par[\"max_depth\"])autoGBM_BestParams['Bayes_min_rows'] &lt;- as.numeric(bayesGridSearch$Best_Par[\"min_rows\"])autoGBM_BestParams['Bayes_sample_rate'] &lt;- as.numeric(bayesGridSearch$Best_Par[\"sample_rate\"])autoGBM_BestParams['Bayes_col_sample_rate'] &lt;- as.numeric(bayesGridSearch$Best_Par[\"col_sample_rate\"])",
                  "url": "/gridsearch/2018/06/14/bayesianGridSearch.html"
                }
                ,
              
                "machineleraning-2018-06-13-rautoml-html": {
                  "title": "자동머신러닝(rAutoML) R패키지 개발",
                  "author": "",
                  "category": "MachineLeraning",
                  "content": "데이터 분석은 1) 데이터 전처리 영역과 2) 모델링 영역으로 구분할 수 있습니다. DS랩에서 개발한 rAutoML(Auto Machine Learning in R)은 모델링 영역을 자동화 해주는 R패키지 입니다. 현재(2018-06) rAutoML에서 제공하는 머신러닝 알고리즘은 H2OGBM이고 추후 H2ORF, H2OXGB 등 추가 될 예정입니다.rAutoML의  학습 프로세스는 다음과 같습니다.  H2OGBM_Default : 디폴트 모형 생성  H2OGBM_StopRules : 학습 스탑 규칙 결정 (Cartesian Grid Search)  H2OGBM_CatEncode : 범주형 변수의 최적의 전처리 방법 탐색 (Cartesian Grid Search)  H2OGBM_MaxDepth : max_depth의 최적의 범위 탐색 (Cartesian Grid Search)  H2OGBM_Random : learn_rate, sample_rate, col_sample_rate, min_rows의 최적값 탐색  (Random Grid Search)  H2OGBM_Bayesian : 소수점 단위로 정밀 튜닝 (Bayesian Grid Search)  H2OGBM_Default -&gt; H2OGBM_StopRules -&gt; H2OGBM_CatEncode -&gt; H2OGBM_MaxDepth -&gt; H2OGBM_Random -&gt; H2OGBM_BayesianrAutoML패키기를 사용한 GBM모형 튜닝 결과            models      auc      logloss                  H2OGBM_Default      0.9136564      0.2006527              H2OGBM_StopRules      0.8995600      0.2097254              H2OGBM_CatEncode      0.9154616      0.1566602              H2OGBM_MaxDepth      0.9166058      0.1754864              H2OGBM_Random      0.9225640      0.1522216              H2OGBM_Bayesian      0.9262237      0.1591523      학습 데이터 소개  churn dataset  3333 rows  Y is binary, X consists of 15 numeric and 4 categorical features  출처 : yhat (https://github.com/yhat/demo-churn-pred/blob/master/model/churn.csv)rAutoML패키지 설치 방법library(devtools)install_github(\"2econsulting/rAutoML\")library(rAutoML)",
                  "url": "/machineleraning/2018/06/13/rAutoML.html"
                }
                ,
              
                "featureselection-2018-06-13-rautofs-html": {
                  "title": "자동변수선택(rAutoFS) R패키지 개발",
                  "author": "",
                  "category": "featureSelection",
                  "content": "h2o.automl(h2o 3.20)는 여러 기초 모델을 생성하고 생성 된 기초 모델을 앙상블하여 보다 우수한 예측 모델을 생성하는 h2o패키지 함수입니다. 여기서 기초 모델을 앙상블할 경우 예측 성능이 높아지는데 이 경우 모델 위에 모델을 쌓는 방식이기 때문에 변수 중요도를 산출할 수 없다는 단점이 존재합니다.rAutoFS(Auto Feature Selection in R)는 이러한 단점을 보완하는 차원에서 개발되었습니다. rAutoFS는 h2o.automl을 사용하여 변수 중요도를 산출합니다. 변수 중요도 산출 로직은 심플합니다. 기초 모델의 변수 중요도를 종합하여 변수 종합 순위를 도출하고 이를 기반으로 변수 중요도를 산출합니다.  h2o.automl학습을 통해서 다수의 예측 모델 생성  생성 된 예측 모델에서 예측 성능이 높은 TOP N개의 모델을 선택 (num_of_model)  TOP N개의 모델의 변수 중요도 도출  도출 된 변수 중요도을 기준으로 vote방식으로 h2o.automl의 변수 중요도 종합rAutoFS::autoFS의 변수 중요도 결과는 다음과 같습니다. (패키지 example)            rank      vi_GBM14      vi_GBM0      vi_GBM1      vi_GBM23      vi_GBM55      vi                  1      Day.Charge      State      State      State      State      State              2      State      Day.Charge      Day.Charge      Day.Charge      Day.Charge      Day.Charge              3      CustServ.Calls      CustServ.Calls      CustServ.Calls      Day.Mins      Eve.Mins      CustServ.Calls              4      Int.l.Plan      Day.Mins      Day.Mins      CustServ.Calls      Int.l.Plan      Int.l.Plan              5      Day.Mins      Eve.Mins      Eve.Mins      Eve.Mins      Night.Mins      Eve.Mins              6      Intl.Charge      Int.l.Plan      Int.l.Plan      Intl.Calls      Intl.Calls      Int.l.Plan              7      Eve.Charge      Intl.Calls      Intl.Calls      Int.l.Plan      Night.Calls      Intl.Calls              8      VMail.Plan      Eve.Charge      Intl.Charge      Intl.Charge      CustServ.Calls      Intl.Charge              9      Intl.Calls      VMail.Message      Eve.Charge      Eve.Charge      Intl.Charge      Eve.Charge              10      Eve.Mins      Intl.Charge      VMail.Message      Intl.Mins      Day.Mins      Eve.Mins              11      Night.Mins      Intl.Mins      Intl.Mins      VMail.Plan      Account.Length      Intl.Mins              12      Night.Charge      VMail.Plan      VMail.Plan      Day.Calls      Eve.Calls      VMail.Plan              13      Intl.Mins      Night.Mins      Night.Mins      Night.Charge      Night.Charge      Night.Mins              14      Eve.Calls      Night.Charge      Night.Charge      VMail.Message      Intl.Mins      Night.Charge              15      Account.Length      Night.Calls      Account.Length      Night.Calls      Day.Calls      Account.Length              16      Night.Calls      Day.Calls      Night.Calls      Night.Mins      VMail.Plan      Night.Calls              17      Day.Calls      Account.Length      Day.Calls      Account.Length      Eve.Charge      Day.Calls              18      VMail.Message      Eve.Calls      Eve.Calls      Eve.Calls      Area.Code      Eve.Calls              19      Area.Code      Area.Code      Area.Code      Area.Code      VMail.Message      Area.Code      rAutoFS 설치 방법library(devtools)install_github(\"jacobgreen1984/rAutoFE\")library(rAutoFE)rAutoFS 실행 방법library(rAutoFS)library(h2o)h2o.init()data(churn, package = \"rAutoFS\")data_hex &lt;- as.h2o(churn)y = \"Churn.\"x = colnames(data_hex)[colnames(data_hex)!=y]autoFS(data_hex, x, y, num_of_model=5, num_of_vi=10)",
                  "url": "/featureselection/2018/06/13/rAutoFS.html"
                }
                ,
              
                "featureengineering-2018-06-13-rautofe-html": {
                  "title": "자동변수생성(rAutoFE) R패키지 개발",
                  "author": "",
                  "category": "featureEngineering",
                  "content": "데이터 분석에서 파생변수를 생성하는 과정은 매우 중요하고 노력과 시간이 많이 필요한 작업입니다.  We spent most of our efforts in feature engineering.  – Xavier Cohort, after winning one of many Kaggle competitions  … some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.  – Pedro Domingos, A Few Useful Things to Know about Machine LearningrAutoFE 소개rAutoFE(auto feature engineering in R)는 다양한 변수를 자동으로 생성해주는 R패키지 입니다.rAutoFE 파생변수 목록  numeric feature transformation  numeric feature binning  categorical feature encoding (frequency-based)  categorical feature encoding (target-based)  weight of evidence features  interaction features  reduce the number of levels for catogorical featuresrAutoFE 패키지 설치 방법library(devtools)install_github(\"2econsulting/rAutoFE\")library(rAutoFE)rAutoFE 패키지 사용 방법library(data.table)library(rAutoFE)library(rAutoFS)library(h2o)savePath &lt;- \"c:/tmp\"dir.create(savePath)data(churn)churn &lt;- as.data.table(churn)churn[, Area.Code:=as.factor(Area.Code)]splits &lt;- splitFrame(dt=churn, ratio = c(0.5, 0.2), seed=1234)train &lt;- splits[[1]]valid &lt;- splits[[2]]test  &lt;- splits[[3]]y = \"Churn.\"x = colnames(train)[colnames(train)!=y]h2o.init()dataset &lt;- autoFE(train=train, valid=valid, test=test, x=x, y=y, savePath=savePath, verbose=TRUE)",
                  "url": "/featureengineering/2018/06/13/rAutoFE.html"
                }
                ,
              
                "github-2018-06-13-makegithubblog-html": {
                  "title": "깃허브 블로그 만드는 방법",
                  "author": "",
                  "category": "github",
                  "content": "깃허브 계정과 연동되는 블로그 생성 방법을 공유합니다.      git 설치 https://gitforwindows.org/        ruby 설치 (jekyll 설치 하려면 필요)https://rubyinstaller.org/downloads/        jekyll 설치 gem install jekyll        github페이지에서 새로운 repository 생성, 이름은 반드시 아래의 형식을 따라야 함 [깃허브유저명].github.io  예. 2econsulting.github.io    로컬 컴퓨터 특정 폴더(C:\\Users\\jacob\\Documents\\GitHub\\2econsulting\\2econsulting.github.io)에 clone 하기    cd C:\\Users\\jacob\\Documents\\GitHub\\2econsultinggit clone https://github.com/2econsulting/2econsulting.github.io.git        jekyll themes 중에서 하나 선택 후 테마파일(zip) 해당 폴더에 다운로드http://jekyllthemes.org/    다운로드 파일 압축 풀고 commit &amp; push하면 깃허브 블러그 생성 완료    git statusgit add .git commit -m \"post upload\"git push origin master     기타, 블로그에 댓글 기능 추가http://recoveryman.tistory.com/391?category=635733",
                  "url": "/github/2018/06/13/makeGithubBlog.html"
                }
                ,
              
                "github-2018-06-13-howtowritepost-html": {
                  "title": "깃허브 블로그 글 쓰는 방법",
                  "author": "",
                  "category": "github",
                  "content": "깃허브 블로그 폴더(2econsulting.github.io/_posts/2018)에 마크다운 파일을 작성해서 저장합니다.파일 저장 포멧은 다음과 같습니다. “yyyy-mm-dd-파일명.markdown” 예. 2018-06-13-sample.markdown파일 저장 후, commit &amp; push하면 글이 업로드 됩니다.$git status$git add .$git commit -m \"post upload\"$git push origin master ",
                  "url": "/github/2018/06/13/howToWritePost.html"
                }
                
              
            };
          </script>

          <script src="/assets/js/lunr.min.js"></script>
          <script src="/assets/js/search.js"></script>

        </div>

        <div class="col-md-4" style="left:5%">
            <h4 class="sidebar-title">깃허브 저장소</h4>


<div class="card text-center">
    <div class="thumbnail">
        <div class="card-image geopattern" data-pattern-id="R_CustomerSegmentation">
            <div class="card-image-cell">
                <h3 class="card-title">
                    <a href="https://github.com/jacobgreen4477/R_CustomerSegmentation" target="_blank">R_CustomerSegmentation</a>
                </h3>
            </div>
        </div>
        <div class="caption">
            <div class="card-description">
                <p class="card-text"></p>
            </div>
            <div class="card-text">
                <span data-toggle="tooltip" class="meta-info" title="2 stars">
                    <span class="octicon octicon-star"></span> 2
                </span>
                <span data-toggle="tooltip" class="meta-info" title="1 forks">
                    <span class="octicon octicon-git-branch"></span> 1
                </span>
                <span data-toggle="tooltip" class="meta-info" title="Last updated：2019-01-02 07:01:34 UTC">
                    <span class="octicon octicon-clock"></span>
                    <time datetime="2019-01-02 07:01:34 UTC" title="2019-01-02 07:01:34 UTC">2019-01-02</time>
                </span>
            </div>
        </div>
    </div>
</div>

<div class="card text-center">
    <div class="thumbnail">
        <div class="card-image geopattern" data-pattern-id="self-study">
            <div class="card-image-cell">
                <h3 class="card-title">
                    <a href="https://github.com/jacobgreen4477/self-study" target="_blank">self-study</a>
                </h3>
            </div>
        </div>
        <div class="caption">
            <div class="card-description">
                <p class="card-text"></p>
            </div>
            <div class="card-text">
                <span data-toggle="tooltip" class="meta-info" title="1 stars">
                    <span class="octicon octicon-star"></span> 1
                </span>
                <span data-toggle="tooltip" class="meta-info" title="1 forks">
                    <span class="octicon octicon-git-branch"></span> 1
                </span>
                <span data-toggle="tooltip" class="meta-info" title="Last updated：2018-10-25 12:39:09 UTC">
                    <span class="octicon octicon-clock"></span>
                    <time datetime="2018-10-25 12:39:09 UTC" title="2018-10-25 12:39:09 UTC">2018-10-25</time>
                </span>
            </div>
        </div>
    </div>
</div>

<div class="card text-center">
    <div class="thumbnail">
        <div class="card-image geopattern" data-pattern-id="tmp">
            <div class="card-image-cell">
                <h3 class="card-title">
                    <a href="https://github.com/jacobgreen4477/tmp" target="_blank">tmp</a>
                </h3>
            </div>
        </div>
        <div class="caption">
            <div class="card-description">
                <p class="card-text"></p>
            </div>
            <div class="card-text">
                <span data-toggle="tooltip" class="meta-info" title="0 stars">
                    <span class="octicon octicon-star"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="0 forks">
                    <span class="octicon octicon-git-branch"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="Last updated：2018-10-02 01:51:20 UTC">
                    <span class="octicon octicon-clock"></span>
                    <time datetime="2018-10-02 01:51:20 UTC" title="2018-10-02 01:51:20 UTC">2018-10-02</time>
                </span>
            </div>
        </div>
    </div>
</div>

<div class="card text-center">
    <div class="thumbnail">
        <div class="card-image geopattern" data-pattern-id="R_MLMC">
            <div class="card-image-cell">
                <h3 class="card-title">
                    <a href="https://github.com/jacobgreen4477/R_MLMC" target="_blank">R_MLMC</a>
                </h3>
            </div>
        </div>
        <div class="caption">
            <div class="card-description">
                <p class="card-text">Machine Learning Master Code</p>
            </div>
            <div class="card-text">
                <span data-toggle="tooltip" class="meta-info" title="0 stars">
                    <span class="octicon octicon-star"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="0 forks">
                    <span class="octicon octicon-git-branch"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="Last updated：2018-11-13 23:46:38 UTC">
                    <span class="octicon octicon-clock"></span>
                    <time datetime="2018-11-13 23:46:38 UTC" title="2018-11-13 23:46:38 UTC">2018-11-13</time>
                </span>
            </div>
        </div>
    </div>
</div>

<div class="card text-center">
    <div class="thumbnail">
        <div class="card-image geopattern" data-pattern-id="TDWI">
            <div class="card-image-cell">
                <h3 class="card-title">
                    <a href="https://github.com/jacobgreen4477/TDWI" target="_blank">TDWI</a>
                </h3>
            </div>
        </div>
        <div class="caption">
            <div class="card-description">
                <p class="card-text"></p>
            </div>
            <div class="card-text">
                <span data-toggle="tooltip" class="meta-info" title="0 stars">
                    <span class="octicon octicon-star"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="0 forks">
                    <span class="octicon octicon-git-branch"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="Last updated：2018-09-22 02:26:59 UTC">
                    <span class="octicon octicon-clock"></span>
                    <time datetime="2018-09-22 02:26:59 UTC" title="2018-09-22 02:26:59 UTC">2018-09-22</time>
                </span>
            </div>
        </div>
    </div>
</div>

<div class="card text-center">
    <div class="thumbnail">
        <div class="card-image geopattern" data-pattern-id="rAutoML">
            <div class="card-image-cell">
                <h3 class="card-title">
                    <a href="https://github.com/jacobgreen4477/rAutoML" target="_blank">rAutoML</a>
                </h3>
            </div>
        </div>
        <div class="caption">
            <div class="card-description">
                <p class="card-text">Auto Machine Learning in R</p>
            </div>
            <div class="card-text">
                <span data-toggle="tooltip" class="meta-info" title="0 stars">
                    <span class="octicon octicon-star"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="0 forks">
                    <span class="octicon octicon-git-branch"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="Last updated：2019-01-02 07:01:28 UTC">
                    <span class="octicon octicon-clock"></span>
                    <time datetime="2019-01-02 07:01:28 UTC" title="2019-01-02 07:01:28 UTC">2019-01-02</time>
                </span>
            </div>
        </div>
    </div>
</div>

<div class="card text-center">
    <div class="thumbnail">
        <div class="card-image geopattern" data-pattern-id="rAutoFS">
            <div class="card-image-cell">
                <h3 class="card-title">
                    <a href="https://github.com/jacobgreen4477/rAutoFS" target="_blank">rAutoFS</a>
                </h3>
            </div>
        </div>
        <div class="caption">
            <div class="card-description">
                <p class="card-text">Auto Feature Selection in R</p>
            </div>
            <div class="card-text">
                <span data-toggle="tooltip" class="meta-info" title="0 stars">
                    <span class="octicon octicon-star"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="0 forks">
                    <span class="octicon octicon-git-branch"></span> 0
                </span>
                <span data-toggle="tooltip" class="meta-info" title="Last updated：2019-01-02 07:01:29 UTC">
                    <span class="octicon octicon-clock"></span>
                    <time datetime="2019-01-02 07:01:29 UTC" title="2019-01-02 07:01:29 UTC">2019-01-02</time>
                </span>
            </div>
        </div>
    </div>
</div>

<script>
    $(document).ready(function(){

        // Enable bootstrap tooltip
        $("body").tooltip({ selector: '[data-toggle=tooltip]' });

        $('.geopattern').each(function(){
            $(this).geopattern($(this).data('pattern-id'));
        });

    });
</script>
        </div>

    </div>

</section>
        </div>

    <footer class="container">

    <div class="site-footer">

        <div class="pull-right">
            <a href="javascript:window.scrollTo(0,0)" >TOP</a>
        </div>

    </div>

    <!-- Third-Party JS -->
    <script type="text/javascript" src="/bower_components/geopattern/js/geopattern.min.js"></script>

    <!-- My JS -->
    <script type="text/javascript" src="/assets/js/script.js"></script>

    

    

</footer>


    </body>

</html>
